{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h69jtVpbtlqp"
      ],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qzz8VxBmcCP"
      },
      "source": [
        "# Ð¡ÐµÐ¼Ð¸Ð½Ð°Ñ€ 4 â€“ Ð›Ð¸Ð½ÐµÐ¹Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð·Ð°Ð´Ð°Ñ‡Ð°Ñ… ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHIDwk_omcCQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIZnmyhM622x"
      },
      "source": [
        "# 1. ÐŸÐ¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð·Ð°Ð´Ð°Ñ‡Ð¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0s4kCH5Jfga"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1Pswe7OKfk75MvJa6kmIRJn6Dq4LhrPTX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nIJ87Z3K9GI"
      },
      "source": [
        "Ð“Ð´Ðµ Ð»Ð¸Ð½ÐµÐ¹Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ - ÑÑ‚Ð¾: $$ \\hat{y} = f(x) = \\theta_0*1 + \\theta_1*x_1 + ... + \\theta_n*x_n = \\theta^T*X$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0RU2rp7660u"
      },
      "source": [
        "# 1. ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1OigmyZA3W0"
      },
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTbbEpwjA3W3"
      },
      "source": [
        "data = fetch_olivetti_faces()\n",
        "data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1jpuSF7A3W6"
      },
      "source": [
        "X, y = data.data, data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqbDv4-RE9C4"
      },
      "source": [
        "n_row, n_col = 2, 3\n",
        "n_components = n_row * n_col\n",
        "image_shape = (64, 64)\n",
        "rng = 0\n",
        "\n",
        "# #############################################################################\n",
        "# Load faces data\n",
        "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True,\n",
        "                                random_state=rng)\n",
        "n_samples, n_features = faces.shape\n",
        "\n",
        "def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray):\n",
        "    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
        "    plt.suptitle(title, size=16)\n",
        "    for i, comp in enumerate(images):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        vmax = max(comp.max(), -comp.min())\n",
        "        plt.imshow(comp.reshape(image_shape), cmap=cmap,\n",
        "                   interpolation='nearest',\n",
        "                   vmin=-vmax, vmax=vmax)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDgt8NqnFFce"
      },
      "source": [
        "plot_gallery(\"Olivetti faces\", faces[:n_components])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi2ZvhdlFr2n"
      },
      "source": [
        "### ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¼ Ð·Ð°Ð²ÐµÐ´Ð¾Ð¼Ð¾ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ (3 ÐºÐ»Ð°ÑÑÐ°)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7csv-XQl9yKX"
      },
      "source": [
        "indx_0 = np.where(y == 0)[0]\n",
        "indx_1 = np.where(y == 1)[0][:8]\n",
        "print(indx_0)\n",
        "print(indx_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAey7Ckh9Mzs"
      },
      "source": [
        "indx_2 = np.where(y == 2)[0][:3]\n",
        "indx_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iP6edIc-YS4"
      },
      "source": [
        "X = X[np.concatenate((np.concatenate((indx_1, indx_0)), indx_2))]\n",
        "y = y[np.concatenate((np.concatenate((indx_1, indx_0)), indx_2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1QZBhfPA3W_"
      },
      "source": [
        "print('Ð’ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ðµ {} Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð¸ {} Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°'.format(X.shape[0], X.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0FWjkg0A3XK"
      },
      "source": [
        "## Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ð¼ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ Ð½Ð° Ð´Ð²Ðµ Ñ‡Ð°ÑÑ‚Ð¸: Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÑƒÑŽ Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv-_k73lA3XK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPnAuqZAA3XM"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    train_size=0.5,\n",
        "                                                    test_size=0.5,\n",
        "                                                    shuffle=True,\n",
        "                                                   random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CMsIzw7A3XP"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COoieQ2MA3XR"
      },
      "source": [
        "Ð—Ð°Ð´Ð°Ð´Ð¸Ð¼ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOx-hiNVA3XS"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ec_5nEA3XT"
      },
      "source": [
        "knn.fit(X_train, y_train)\n",
        "knn_predictons = knn.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu04KvGEA3XW"
      },
      "source": [
        "preds = pd.DataFrame(y_test, columns=['True'])\n",
        "preds['knn_pred'] = knn_predictons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHEz4InXA3XY"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsu7abdvGRb-"
      },
      "source": [
        "Ð§Ñ‚Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ?\n",
        "\n",
        "---\n",
        "\n",
        "ÐÐ° 0 Ð¸ 1 ÐºÐ»Ð°ÑÑÐ° ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð¾Ñ‚Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾, Ð½Ð¾ 2 ÐºÐ»Ð°ÑÑ Ð¾Ð½ Ð½Ðµ Ð²Ð¸Ð´ÐµÐ» Ð¸ Ð½Ðµ ÑÐ¼Ð¾Ð³ ÐµÐ³Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7hkStFb5CGH"
      },
      "source": [
        "## ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð´Ð¾Ð»ÑŽ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUj2vteGA3Xa"
      },
      "source": [
        "def accuracy(true, predictions):\n",
        "    acc = predictions[true == predictions].shape[0]/true.shape[0] # Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ\n",
        "    return acc\n",
        "accuracy(y_test, knn_predictons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07d2-N1BA3Xc"
      },
      "source": [
        "#Ð¢Ð¾Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¼Ð¸ sklearn:\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, knn_predictons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqawSQGfA3Xl"
      },
      "source": [
        "## ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² (precision)\n",
        "Ð±ÐµÐ· ÑƒÑ‡ÐµÑ‚Ð° Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð² (Ð²ÑÐµÐ³Ð¾ TP/ (Ð²ÑÐµÐ³Ð¾ TP + Ð²ÑÐµÐ³Ð¾ FP)):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llcN4SwJA3Xl"
      },
      "source": [
        "def precision(true, predictions):\n",
        "    # Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ:\n",
        "    # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÐºÐ»Ð°ÑÑ 1 ÐºÐ°Ðº True\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    for i in range(len(true)):\n",
        "      if true[i] == 1 and predictions[i] == 1:\n",
        "        TP = TP + 1\n",
        "      elif predictions [i] != true[i] and predictions[i] == 1:\n",
        "        FP = FP + 1\n",
        "    prec = TP/(TP+FP)\n",
        "    return prec\n",
        "precision(y_test, knn_predictons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Omc5yNA3Xn"
      },
      "source": [
        "Ð¢Ð¾Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¼Ð¸ sklearn:\n",
        "\n",
        "---\n",
        "\n",
        "'binary':\n",
        " Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ°, ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð³Ð¾ pos_label. Ð­Ñ‚Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ð¾, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð¢Ð°Ñ€Ð³ÐµÑ‚ (y_ {true, pred}) ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð´Ð²Ð¾Ð¸Ñ‡Ð½Ñ‹Ð¼.\n",
        "\n",
        "'micro':\n",
        "Ð¿Ð¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ TP Ð¸ FP.\n",
        "\n",
        "'macro':\n",
        "Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ° Ð¸ Ð±ÐµÑ€ÐµÑ‚ Ð¸Ñ… Ð½ÐµÐ²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð¾Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐµ. ÐŸÑ€Ð¸ ÑÑ‚Ð¾Ð¼ Ð½Ðµ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½Ñ ÐºÐ»Ð°ÑÑÐ¾Ð².\n",
        "\n",
        "'weighted':\n",
        "Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ° Ð¿Ð¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ÑÑ TP Ð¸ FP Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ Ð¸ Ð±ÐµÑ€ÐµÑ‚ÑÑ Ð¸Ñ… ÑÑ€ÐµÐ´Ð½ÐµÐ²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ\n",
        "\n",
        "'samples':\n",
        "Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ð° Ð¸ Ð±ÐµÑ€ÐµÑ‚ÑÑ Ð¸Ñ… ÑÑ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXx0-R1YA3Xo"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_test, knn_predictons, labels=[1], average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJEIfKsCA3Xt"
      },
      "source": [
        "## ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð¿Ð¾Ð»Ð½Ð¾Ñ‚Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² (recall)\n",
        "Ð±ÐµÐ· ÑƒÑ‡ÐµÑ‚Ð° Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð² (Ð²ÑÐµÐ³Ð¾ TP/(Ð²ÑÐµÐ³Ð¾ TP + Ð²ÑÐµÐ³Ð¾ FN)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFwTKdSrA3Xu"
      },
      "source": [
        "def recall(true, predictions):\n",
        "    # Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ:\n",
        "    TP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(true)):\n",
        "      if true[i] == 1 and predictions[i] == 1:\n",
        "        TP = TP + 1\n",
        "      elif predictions [i] != 1 and true[i] == 1:\n",
        "        FN = FN + 1\n",
        "    rec = TP/(TP+FN)\n",
        "    return rec\n",
        "recall(y_test, knn_predictons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLATItdjA3Xw"
      },
      "source": [
        "Ð¢Ð¾Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¼Ð¸ sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6ctcWBkA3Xw"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test, knn_predictons, labels=[1], average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5ubxAAZA3Xy"
      },
      "source": [
        "## ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ F-score\n",
        "2 * precision * recall / (precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9f0bIA6A3Xy"
      },
      "source": [
        "def F1_score(true, predictions):\n",
        "    # Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ:\n",
        "    f1 = 2*(recall(true, predictions)*precision(true, predictions))/(recall(true, predictions)+precision(true, predictions))\n",
        "    return f1\n",
        "F1_score(y_test, knn_predictons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWnBqOJbA3X0"
      },
      "source": [
        "Ð¢Ð¾Ð¶Ðµ ÑÐ°Ð¼Ð¾Ðµ ÑÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¼Ð¸ sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY1ree5aA3X0"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, knn_predictons, labels=[1], average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjmzJpCrA3X2"
      },
      "source": [
        "## Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¸Ð¼ ROC curve:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyd-IMihA3X3"
      },
      "source": [
        "Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾, Ð² Ð¾Ñ‚Ð»Ð¸Ñ‡Ð°Ðµ Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ð¹, Ð½Ð°Ð¼ Ð¿Ð¾Ð½Ð°Ð´Ð¾Ð±ÑÑ‚ÑÑ Ð½Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ð° Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð½Ð°Ð´Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ»Ð°ÑÑÐ°Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²Ñ‹Ð´Ð°ÐµÑ‚."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb4mchwUA3X3"
      },
      "source": [
        "probs = knn.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UgvQFtsA3X5"
      },
      "source": [
        "Ð¢Ð°ÐºÐ¶Ðµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð±Ð¾ Ð±Ð¸Ð½Ð°Ñ€Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼ÐµÑ‚ÐºÐ¸ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð´Ð»Ñ Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚Ð° TPR Ð¸ FPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmVasJQNA3X6"
      },
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "counts = np.unique(y, return_counts=True)\n",
        "y_test_bin = label_binarize(y_test, classes=counts[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILu8O18SA3X7"
      },
      "source": [
        "y_test_bin[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1BMDFPWA3X9"
      },
      "source": [
        "Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ TPR Ð¸ FPR Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJIhd9k1A3X9"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in counts[0]:\n",
        "    fpr[i], tpr[i], threshold = roc_curve(y_test_bin[:, i], probs[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dOfmGnYA3X_"
      },
      "source": [
        "roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErOd3i7DA3YB"
      },
      "source": [
        "fpr[\"micro\"], tpr[\"micro\"], threshold = roc_curve(y_test_bin.ravel(), probs.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "roc_auc[\"micro\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u2385zHA3YD"
      },
      "source": [
        "def plot_roc_curve(index=8):\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr[index], tpr[index], color='darkorange',\n",
        "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[index])\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic for class {}'.format(index))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGgvhVdIA3YE"
      },
      "source": [
        "plot_roc_curve(\"micro\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmFUt5cd-0QL"
      },
      "source": [
        "# Ð›Ð¸Ð½ÐµÐ¹Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸\n",
        "Ð’ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð±ÑƒÐ´ÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸ Ñ†Ð¸Ñ„Ñ€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95hdY9WQ-0QL"
      },
      "source": [
        "# Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUiVAqYs-0QM"
      },
      "source": [
        "X = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmQWWnf_-0QO"
      },
      "source": [
        "# ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð½Ð° ÐºÐ¾Ð»-Ð²Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEITJX2H-0QP"
      },
      "source": [
        "# Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ, Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼, ÐºÐ°Ðº Ð²Ñ‹Ð»ÑÐ´Ð¸Ñ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ Ð½Ð°ÑˆÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸\n",
        "target_image_id = np.random.randint(X.shape[0])\n",
        "\n",
        "plt.figure(figsize=(4,2))\n",
        "plt.imshow(X[target_image_id].reshape((8, 8)), cmap='binary')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title('True class: '+ str(y[target_image_id]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P17AIR1-0QR"
      },
      "source": [
        "# ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ð½Ð° Ð±Ð°Ð»Ð°Ð½Ñ ÐºÐ»Ð°ÑÑÐ¾Ð²\n",
        "class_counts = np.unique(y, return_counts=True)\n",
        "\n",
        "pd.DataFrame(class_counts[1], index=class_counts[0], columns=['Counts'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YtXHAXT-0QS"
      },
      "source": [
        "## Ð›Ð¾Ð³Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ñ Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾ÐºÐ»Ð°ÑÑÐ¾Ð²Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEiSkOH_-0QS"
      },
      "source": [
        "# Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð¼ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82axMzty-0QT"
      },
      "source": [
        "# Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ð¼ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ Ð½Ð° Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½ÑƒÑŽ Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                 train_size=0.8, test_size=0.2, shuffle=True,\n",
        "                 random_state=42)\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWfULoE0-0QV"
      },
      "source": [
        "*Ð›Ð¾Ð³Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ñ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ñ€ÐµÑˆÐ°Ñ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¼Ð½Ð¾Ð³Ð¾ÐºÐ»Ð°ÑÑÐ¾Ð²Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸. ÐšÐ»Ð°ÑÑ ``LogisticRegression`` Ð¿Ð¾Ð·Ð²Ð»ÑÐµÑ‚ ÑÑ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð´Ð²ÑƒÐ¼Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð°Ð¼Ð¸:*\n",
        "- Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ One vs Rest (Ñ‚.Ðµ. ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ Ð¾Ñ‚Ð´ÐµÐ»ÑÐµÑ‚ÑÑ Ð¾Ñ‚ Ð²ÑÐµÑ… Ð´Ñ€ÑƒÐ³Ð¸Ñ…). ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ `multi_class='ovr'`.*\n",
        "- One vs One: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ ÐºÑ€Ð¾ÑÑ-ÑÐ½Ñ‚Ñ€Ð¾Ð¿Ð¸ÑŽ (Ð¾Ñ†ÐµÐ½Ð¸Ð²Ð°ÐµÑ‚ÑÑ ÑÑ€Ð°Ð·Ñƒ Ð²ÐµÐºÑ‚Ð¾Ñ€ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð¿Ñ€Ð¸Ð½Ð°Ð´Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ»Ð°ÑÑÐ°Ð¼). ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ `multi_class='multinomial'`.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2_usOtj6kq_"
      },
      "source": [
        "#### One vs Rest\n",
        "\n",
        "\n",
        "Find ð¾ âˆ’ 1 classifiers ð‘“ , ð‘“ , ... , ð‘“ 12 ð¾âˆ’1  \n",
        "- ð‘“ classifies1ð‘£ð‘ {2,3,...,ð¾} 1\n",
        "- ð‘“ classifies2ð‘£ð‘ {1,3,...,ð¾} 2\n",
        "- ...\n",
        "- ð‘“ classifiesð¾âˆ’1ð‘£ð‘ {1,2,...,ð¾âˆ’2}\n",
        "- ð¾âˆ’1\n",
        "- Points not classified to classes {1,2, ... , ð¾ âˆ’ 1} are put to class ð¾\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KFaDE6W-0QV"
      },
      "source": [
        "#### One vs One (Cross-entropy)\n",
        "\n",
        "\n",
        "Ð’ ÑÐ»ÑƒÑ‡Ð°Ðµ Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ:\n",
        "$$ \\sum_{i=1}^l \\bigl( y_i \\log a_i - (1-y_i) \\log (1-a_i) \\bigr)  \\rightarrow min$$  \n",
        "$a_i$ â€“ Ð¾Ñ‚Ð²ÐµÑ‚ (Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ) Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð° Ð½Ð° i-Ð¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ðµ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ñ€Ð¸Ð½Ð°Ð´Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ Ðº ÐºÐ»Ð°ÑÑÑƒ $y_i$\n",
        "\n",
        "ÐžÐ±Ð¾Ð±Ñ‰Ð°ÐµÑ‚ÑÑ Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾Ð¼ÐµÑ€Ð½Ð¾Ð³Ð¾ ÑÐ»ÑƒÑ‡Ð°Ñ:\n",
        "$$-\\frac{1}{q} \\sum_{i=1}^q \\sum_{j=1}^l y_{ij} \\log a_{ij} \\rightarrow min $$\n",
        "Ð³Ð´Ðµ  \n",
        "$q$ â€“ Ñ‡Ð¸ÑÐ»Ð¾ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ,  \n",
        "$l$ â€“ Ñ‡Ð¸ÑÐ»Ð¾ ÐºÐ»Ð°ÑÑÐ¾Ð²,   \n",
        "$a_{ij}$ â€“ Ð¾Ñ‚Ð²ÐµÑ‚ (Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ) Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð° Ð½Ð° i-Ð¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ðµ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ñ€Ð¸Ð½Ð°Ð´Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ ÐµÐ³Ð¾ Ðº j-Ð¼Ñƒ ÐºÐ»Ð°ÑÑÑƒ\n",
        "\n",
        "__ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:__\n",
        "\n",
        "- Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð² Ð¿Ð¾Ð¸ÑÐºÐµ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð°, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ñ‹ Ð¸ Ð¿Ð»Ð°Ñ‚Ð¾"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc0uO1ep7nT9"
      },
      "source": [
        "## Solvers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNuGUp7V-0Qa"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=19r1jQUiEStMMrGJCWAxzgjFiG4bvXIZ3)\n",
        "\n",
        "Source: [User Guide](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDtwZK3f-0Qb"
      },
      "source": [
        "### Liblinear\n",
        "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð¿Ð¾ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ð½Ñ‚Ð½Ñ‹Ð¹ ÑÐ¿ÑƒÑÐº.\n",
        "ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:\n",
        "- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ€ÑƒÐµÐ¼ Ð»ÑŽÐ±Ñ‹Ð¼Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€ Ð²ÐµÑÐ¾Ð²\n",
        "- ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ÑÐµÐ¼ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ i Ð¸Ð· Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ð° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²:\n",
        "    - Ñ„Ð¸ÐºÑÐ¸Ñ€ÑƒÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð²ÑÐµÑ… Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… ÐºÑ€Ð¾Ð¼Ðµ $x_i$\n",
        "    - Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ð¼ Ð¾Ð´Ð½Ð¾Ð¼ÐµÑ€Ð½ÑƒÑŽ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ $x_i$, Ð»ÑŽÐ±Ñ‹Ð¼ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð¼ Ð¾Ð´Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸\n",
        "    - ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð° Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¹ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ðµ, Ñ‚Ð¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð° Ð²ÐµÑÐ¾Ð²\n",
        "\n",
        "ÐšÐ°Ðº ÑÑ‚Ð¾ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚ Ð´Ð»Ñ Ð¼Ð¸Ð½Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»Ð°\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=13J7wRDNmNNeueuT9rciTl2Quw60UYIbv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1gyOEnZ7gj9"
      },
      "source": [
        "__ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸:__\n",
        "1. ÐÐµ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ñ‚ÑÑ\n",
        "2. ÐœÐ¾Ð¶ÐµÑ‚ \"Ð·Ð°ÑÑ‚Ñ€ÑÑ‚ÑŒ\" Ð² Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ðµ\n",
        "3. Ð¡Ð»ÐµÐ´ÑÑ‚Ð²Ð¸Ðµ Ð¿.2 - ÐÐµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ ÐºÑ€Ð¾ÑÑ-ÑÐ½Ñ‚Ñ€Ð¾Ð¿Ð¸Ñ Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾Ð¼ÐµÑ€Ð½Ð¾Ð³Ð¾ ÑÐ»ÑƒÑ‡Ð°Ñ, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð»ÐµÐ³ÐºÐ¾ \"Ð—Ð°ÑÑ‚Ñ€ÐµÐ²Ð°ÐµÑ‚\" Ð² Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð°Ñ…. Ð’Ð¼ÐµÑÑ‚Ð¾ ÑÑ‚Ð¾Ð³Ð¾ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ° ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ (One-vs-Rest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H17nn-nA-0QV"
      },
      "source": [
        "%%time\n",
        "lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB5V1pFE-0QY"
      },
      "source": [
        "accuracy_score(lr.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HNJpbTm-0Qb"
      },
      "source": [
        "%%time\n",
        "len_c = 10\n",
        "param_grid={\n",
        "    'C': np.linspace(0.01, 1, len_c),\n",
        "    'penalty': ['l1', 'l2']\n",
        "    }\n",
        "\n",
        "gs=GridSearchCV(lr,param_grid=param_grid, cv=3,\n",
        "                n_jobs=-1, scoring='accuracy')\n",
        "gs.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szxUSRlA-0Qc"
      },
      "source": [
        "accuracy_score(gs.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAm2KFSUMhsa"
      },
      "source": [
        "def print_cv_results(a, len_gs, params, param_r, param_sep):\n",
        "    d = len(params['param_grid'][param_sep])\n",
        "    ar=np.array(a).reshape(d, len_gs).T\n",
        "\n",
        "    df=pd.DataFrame(ar)\n",
        "\n",
        "    pen_par=params['param_grid'][param_sep]\n",
        "    c_par=params['param_grid'][param_r].tolist()\n",
        "    columns_mapper=dict(zip(range(0, len(pen_par)),pen_par))\n",
        "    row_mapper=dict(zip(range(0, len(c_par)), c_par))\n",
        "\n",
        "    df.rename(columns=columns_mapper, index=row_mapper, inplace=True)\n",
        "\n",
        "    plot = df.plot(title='Mean accuracy rating',grid=True)\n",
        "    plot.set_xlabel(param_r, fontsize=13)\n",
        "    plot.set_ylabel('acc', rotation=0, fontsize=13, labelpad=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTZz6aRI-0Qd"
      },
      "source": [
        "print_cv_results(gs.cv_results_['mean_test_score'],\n",
        "                 len_c, gs.get_params(), 'C','penalty')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IED2tWmPAPx6"
      },
      "source": [
        "### Newton-cg (Newtonâ€™s Method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwn0I3zqAP-i"
      },
      "source": [
        "Ð“ÐµÐ¾Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ Ð¼ÐµÑ‚Ð¾Ð´Ð° ÐÑŒÑŽÑ‚Ð¾Ð½Ð° Ð·Ð°ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ Ð² Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð¶Ð°ÐµÑ‚ÑÑ f(x) ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÐµÐ¹, Ð° Ð·Ð°Ñ‚ÐµÐ¼ Ð´ÐµÐ»Ð°ÐµÑ‚ ÑˆÐ°Ð³ Ðº Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼Ñƒ / Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ñƒ ÑÑ‚Ð¾Ð¹ ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸.\n",
        "\n",
        "ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸:\n",
        "\n",
        "1. Ð—Ð°Ñ‚Ñ€Ð°Ñ‚Ð½Ð¾ Ñ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð·Ñ€ÐµÐ½Ð¸Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñ‹ Ð“ÐµÑÑÐµ (Ñ‚.Ðµ. Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹ Ð²Ñ‚Ð¾Ñ€Ñ‹Ñ… Ñ‡Ð°ÑÑ‚Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð½Ñ‹Ñ…).\n",
        "\n",
        "2. ÐœÐ¾Ð¶ÐµÑ‚ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒÑÑ Ð² ÑÐµÐ´Ð»Ð¾Ð²Ð¾Ð¹ Ñ‚Ð¾Ñ‡ÐºÐµ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¾ Ð¿Ð¾ÑÐ²Ð»ÑÑŽÑ‚ÑÑ Ð¿Ñ€Ð¸ Ð¼Ð½Ð¾Ð³Ð¾Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzWi3r0NM2G8"
      },
      "source": [
        "%%time\n",
        "lr = LogisticRegression(solver='newton-cg', penalty='l2')\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X37PE8ITM2G-"
      },
      "source": [
        "accuracy_score(lr.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDmzDdQlM2G_"
      },
      "source": [
        "%%time\n",
        "len_c = 10\n",
        "param_grid={\n",
        "    'C': np.linspace(0.01, 1, len_c),\n",
        "    'multi_class': ['ovr', 'multinomial']\n",
        "    }\n",
        "\n",
        "gs=GridSearchCV(lr,param_grid=param_grid, cv=3,\n",
        "                n_jobs=-1, scoring='accuracy')\n",
        "gs.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlS2xi32M2HA"
      },
      "source": [
        "accuracy_score(gs.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my6yswHIM2HA"
      },
      "source": [
        "print_cv_results(gs.cv_results_['mean_test_score'],\n",
        "                 len_c, gs.get_params(), 'C','multi_class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds146PvX_L8y"
      },
      "source": [
        "### Lbfgs (Limited-memory Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno Algorithm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx4zJ1et_QNr"
      },
      "source": [
        "ÐÐ½Ð°Ð»Ð¾Ð³ Ð¼ÐµÑ‚Ð¾Ð´Ð° ÐÑŒÑŽÑ‚Ð¾Ð½Ð° (ÐºÐ²Ð°Ð·Ð¸Ð½ÑŒÑŽÑ‚Ð¾Ð½Ð¾Ð²ÑÐºÐ¸Ð¹ Ð¼ÐµÑ‚Ð¾Ð´), Ð½Ð¾ Ð·Ð´ÐµÑÑŒ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° Ð“ÐµÑÑÐµ Ð°Ð¿Ð¿Ñ€Ð¾ÐºÑÐ¸Ð¼Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð°.\n",
        "\n",
        "ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½ÐµÑÐ²Ð½Ð¾ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñ‹.\n",
        "\n",
        "Solver Â«lbfgsÂ» Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð»Ñ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð½Ð°Ð±Ð¾Ñ€Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð½Ð°Ð±Ð¾Ñ€Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÐ½Ð¸Ð¶Ð°ÐµÑ‚ÑÑ ÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ.\n",
        "\n",
        "â€œlbfgsâ€ solver Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² sklearn Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¸Ð·-Ð·Ð° ÐµÐ³Ð¾ ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚Ð¸."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZltAI4M9Chlt"
      },
      "source": [
        "%%time\n",
        "lr = LogisticRegression(solver='lbfgs', penalty='l2')\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-q38hgChlt"
      },
      "source": [
        "accuracy_score(lr.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wakEEbYjChlt"
      },
      "source": [
        "%%time\n",
        "len_c = 10\n",
        "param_grid={\n",
        "    'C': np.linspace(0.01, 1, len_c),\n",
        "    'multi_class': ['ovr', 'multinomial']\n",
        "    }\n",
        "\n",
        "gs=GridSearchCV(lr,param_grid=param_grid, cv=3,\n",
        "                n_jobs=-1, scoring='accuracy')\n",
        "gs.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MkeWbOkChlu"
      },
      "source": [
        "accuracy_score(gs.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6bGo_UChlu"
      },
      "source": [
        "print_cv_results(gs.cv_results_['mean_test_score'],\n",
        "                 len_c, gs.get_params(), 'C','multi_class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4MrsZYZ8EuV"
      },
      "source": [
        "### Stochatic Average Gradient (SAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne_h901Y-0Qe"
      },
      "source": [
        "ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ ÑÐ¿ÑƒÑÐºÐ° Ð¸ ÑÑ‚Ð¾Ñ…Ð°ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾.\n",
        "ÐŸÑ€Ð¸ ÑÑ‚Ð¾Ð¼, Ð¾Ð½ Ð¸Ð¼ÐµÐµÑ‚ Ð½Ð¸Ð·ÐºÑƒÑŽ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÐ²Ð¾Ð¹ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ SGD, Ð½Ð¾ Ð´ÐµÐ»Ð°ÐµÑ‚ ÑˆÐ°Ð³ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð° Ð¿Ð¾ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸ÑŽ Ðº Ð°Ð¿Ð¿Ñ€Ð¾ÐºÑÐ¸Ð¼Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð°:\n",
        "\n",
        "\n",
        "__ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸:__\n",
        "- ÐÐµÑ‚ L1\n",
        "- ÐÐµÐ¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÐ½ Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ðº, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð¸Ð¼ÐµÐµÑ‚ Ð²Ñ‹ÑÐ¾ÐºÑƒÑŽ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYkTJ-QfNLY7"
      },
      "source": [
        "%%time\n",
        "lr = LogisticRegression(solver='sag', penalty='l2')\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UxkHSGwNLY9"
      },
      "source": [
        "accuracy_score(lr.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YDMcniuNLY-"
      },
      "source": [
        "%%time\n",
        "len_c = 10\n",
        "param_grid={\n",
        "    'C': np.linspace(0.01, 1, len_c),\n",
        "    'multi_class': ['ovr', 'multinomial']\n",
        "    }\n",
        "\n",
        "gs=GridSearchCV(lr,param_grid=param_grid, cv=3,\n",
        "                n_jobs=-1, scoring='accuracy')\n",
        "gs.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Cn0N9dNLY_"
      },
      "source": [
        "accuracy_score(gs.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4uwixFZNLZA"
      },
      "source": [
        "print_cv_results(gs.cv_results_['mean_test_score'],\n",
        "                 len_c, gs.get_params(), 'C','multi_class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n069iQlq-0Qf"
      },
      "source": [
        "### Stochatic Average Gradient Augmented (SAGA)\n",
        "\n",
        "SAGA ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð¼ SAG, Ð½Ð¾ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ð¿Ñ†Ð¸ÑŽ non-smooth penalty=l1 (Ñ‚. Ðµ. Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð¸Ð·Ð°Ñ†Ð¸ÑŽ L1).\n",
        "\n",
        "ÐšÑ€Ð¾Ð¼Ðµ Ñ‚Ð¾Ð³Ð¾, ÑÑ‚Ð¾ ÐµÐ´Ð¸Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Solver, Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ð¹ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð¸Ð·Ð°Ñ†Ð¸ÑŽ = \"elasticnet\".\n",
        "\n",
        "[ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ: ](https://www.di.ens.fr/~fbach/Defazio_NIPS2014.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmbVzwEU-0Qf"
      },
      "source": [
        "lr_clf = LogisticRegression(solver='saga', max_iter=1500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9_G1p48-0Qh"
      },
      "source": [
        "%%time\n",
        "len_c = 3\n",
        "param_grid={\n",
        "    'C': np.linspace(0.01, 1, len_c),\n",
        "    #'multi_class': ['ovr', 'multinomial'],\n",
        "    'penalty': ['l1', 'l2']\n",
        "    }\n",
        "\n",
        "gs=GridSearchCV(lr_clf,param_grid=param_grid, cv=3,\n",
        "                n_jobs=-1, scoring='accuracy')\n",
        "gs.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqqd7y9k-0Qi"
      },
      "source": [
        "print_cv_results(gs.cv_results_['mean_test_score'],\n",
        "                 len_c, gs.get_params(), 'C','penalty')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nG-n0C-0Qk"
      },
      "source": [
        "accuracy_score(gs.predict(x_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J74O-qdJYJ80"
      },
      "source": [
        "# Intro to PyTorch (Ð¿Ð¾ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð°Ð¼ [DLÑourse](https://www.dlschool.org/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpXxZ4-4YJ83"
      },
      "source": [
        "[official PyTorch website](https://pytorch.org/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxdjjnqIYJ86"
      },
      "source": [
        "## Syntax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtyozNmmYJ89"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjfLQzEPYJ9B"
      },
      "source": [
        "Some facts about PyTorch:  \n",
        "- dynamic computation graph\n",
        "- handy `torch.nn` and `torchvision` modules for fast neural network prototyping\n",
        "- even faster than TensorFlow on some tasks\n",
        "- allows to use GPU easily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AL-T8TMYJ9D"
      },
      "source": [
        "If PyTorch was a formula, it would be:  \n",
        "\n",
        "$$PyTorch = NumPy + CUDA + Autograd$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_O59VXWYJ9E"
      },
      "source": [
        "(CUDA - [wiki](https://en.wikipedia.org/wiki/CUDA))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWIeTFxSYJ9F"
      },
      "source": [
        "Let's see how we can use PyTorch to operate with vectors and tensors.  \n",
        "\n",
        "Recall that **a tensor** is a multidimensional vector, e.g. :  \n",
        "\n",
        "`x = np.array([1,2,3])` -- a vector = a tensor with 1 dimension (to be more precise: `(1,)`)  \n",
        "`y = np.array([[1, 2, 3], [4, 5, 6]])` -- a matrix = a tensor with 2 dimensions (`(2, 3)` in this case)  \n",
        "`z = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],  \n",
        "               [[1, 2, 3], [4, 5, 6], [7, 8, 9]],  \n",
        "               [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])` -- \"a cube\" (3, 3, 3) = a tensor with 3 dimensions (`(3, 3, 3)` in this case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS97vo7mYJ9G"
      },
      "source": [
        "One real example of 3-dimensional tensor is **an image**, it has 3 dimensions: `height`, `width` and the `channel depth` (= 3 for color images, 1 for a greyscale). You can think of it as of parallelepiped consisting of the real numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEeGGtRiYJ9H"
      },
      "source": [
        "In PyTorch we will use `torch.Tensor` (`FloatTensor`, `IntTensor`, `ByteTensor`) for all the computations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byu7xZtLYJ9J"
      },
      "source": [
        "All tensor types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zilSktmEGgAv"
      },
      "source": [
        "torch.HalfTensor      # 16 Ð±Ð¸Ñ‚, floating point\n",
        "torch.FloatTensor     # 32 Ð±Ð¸Ñ‚Ð°, floating point\n",
        "torch.DoubleTensor    # 64 Ð±Ð¸Ñ‚Ð°, floating point\n",
        "\n",
        "torch.ShortTensor     # 16 Ð±Ð¸Ñ‚, integer, signed\n",
        "torch.IntTensor       # 32 Ð±Ð¸Ñ‚Ð°, integer, signed\n",
        "torch.LongTensor      # 64 Ð±Ð¸Ñ‚Ð°, integer, signed\n",
        "\n",
        "torch.CharTensor      # 8 Ð±Ð¸Ñ‚, integer, signed\n",
        "torch.ByteTensor      # 8 Ð±Ð¸Ñ‚, integer, unsigned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWk2gidNYJ9P"
      },
      "source": [
        "We will use only `torch.FloatTensor()` and `torch.IntTensor()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CllyEKvVYJ9Q"
      },
      "source": [
        "Let's begin to do something!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4HEetsxYJ9Q"
      },
      "source": [
        "* Creating the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVawE9lRYJ9R"
      },
      "source": [
        "a = torch.FloatTensor([1, 2])\n",
        "a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARjaPS_GYJ9W"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXf0akDYJ9Z"
      },
      "source": [
        "b = torch.FloatTensor([[1,2,3], [4,5,6]])\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HTkoIzpYJ9e"
      },
      "source": [
        "b.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJ9L-yFYJ9j"
      },
      "source": [
        "x = torch.FloatTensor(2,3,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWAEP27IYJ9m"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5CsOJ_xYJ9s",
        "scrolled": true
      },
      "source": [
        "x = torch.FloatTensor(100)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIVhvmzZYJ91"
      },
      "source": [
        "x = torch.IntTensor(45, 57, 14, 2)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUzl8DFRYJ95"
      },
      "source": [
        "**Note:** if you create `torch.Tensor` with the following constructor it will be filled with the \"random trash numbers\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX0QcIOzYJ96"
      },
      "source": [
        "x = torch.IntTensor(3, 2, 4)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utra2t4SbdQR"
      },
      "source": [
        "Here is a way to fill a new tensor with zeroes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV3w9lVwYJ-A"
      },
      "source": [
        "x = torch.FloatTensor(3, 2, 4).zero_()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzq1klQuzXA9"
      },
      "source": [
        "## Numpy -> Torch\n",
        "\n",
        "All numpy function have its pair in torch.\n",
        "\n",
        "https://github.com/torch/torch7/wiki/Torch-for-Numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAAmLRwzYJ-E"
      },
      "source": [
        "`np.reshape()` == `torch.view()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spMYG2xXYJ-L"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjL3X3GYJ-H"
      },
      "source": [
        "b.view(3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amVu0N1zYJ-O"
      },
      "source": [
        "**Note:** `torch.view()` creates a new tensor, one the old one remains unchanged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWqyugOSYJ-Q"
      },
      "source": [
        "b.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9CvF56uYJ-U"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t401j1E2YJ-Z"
      },
      "source": [
        "* Change a tensor type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_iDUEH4YJ-Z"
      },
      "source": [
        "a = torch.FloatTensor([1.5, 3.2, -7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzJOrXitYJ-e"
      },
      "source": [
        "a.type_as(torch.IntTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAe3OWWUYJ-i"
      },
      "source": [
        "a.type_as(torch.ByteTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rkatrUeYJ-n"
      },
      "source": [
        "**Note:** `.type_as()` creates a new tensor, the old one remains unchanged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCgDT14MYJ-o"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG1OwtFBYJ-r"
      },
      "source": [
        "* Indexing is just like in `NumPy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prr0EGIYYJ-r"
      },
      "source": [
        "a = torch.FloatTensor([[100, 20, 35], [15, 163, 534], [52, 90, 66]])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBq7JiccYJ-w"
      },
      "source": [
        "a[0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUZzx2F_YJ-2"
      },
      "source": [
        "a[0:2, 0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KffQsYwWYJ_D"
      },
      "source": [
        "**Ariphmetics and boolean operations** and their analogues:  \n",
        "\n",
        "| Operator | Analogue |\n",
        "|:-:|:-:|\n",
        "|`+`| `torch.add()` |\n",
        "|`-`| `torch.sub()` |\n",
        "|`*`| `torch.mul()` |\n",
        "|`/`| `torch.div()` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMpR8T11YJ_D"
      },
      "source": [
        "* Addition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XHkSjEUYJ_D"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "b = torch.FloatTensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td25tuFKYJ_H"
      },
      "source": [
        "a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHka8PxFYJ_N"
      },
      "source": [
        "a.add(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHQj4DbBYJ_Q"
      },
      "source": [
        "b = -a\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLCDzO7iYJ_V"
      },
      "source": [
        "a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_3gVLY3YJ_Z"
      },
      "source": [
        "* Subtraction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PANHq3eFYJ_a"
      },
      "source": [
        "a - b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH7xhdkRYJ_i"
      },
      "source": [
        "a.sub(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOX3dTuZYJ_l"
      },
      "source": [
        "* Multiplication (elementwise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J380CvNGYJ_m"
      },
      "source": [
        "a * b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cixW0jgdYJ_o"
      },
      "source": [
        "a.mul(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-GYTERKYJ_q"
      },
      "source": [
        "* Division (elementwise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUBQns2SYJ_r"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "b = torch.FloatTensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hrKeMjAYJ_v"
      },
      "source": [
        "a / b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpg3YFVPYJ_2"
      },
      "source": [
        "a.div(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeLAbx1tYJ_7"
      },
      "source": [
        "**Note:** all this operations create new tensors, the old tensors remain unchanged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57BFtnlgYJ_8"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UziXyvtDYJ_-"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLpwZPc3YKAC"
      },
      "source": [
        "* Comparison operators:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfRzvw_UYKAC"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "b = torch.FloatTensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1RUTP2BYKAD"
      },
      "source": [
        "a == b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO3HaVIAYKAF"
      },
      "source": [
        "a != b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DExLBj4VYKAH"
      },
      "source": [
        "a < b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_IH_FUNYKAJ"
      },
      "source": [
        "a > b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24nzBJR8YKAM"
      },
      "source": [
        "* Using boolean mask indexing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-xVDslwYKAN"
      },
      "source": [
        "a[a > b]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XatDJF5YYKAQ"
      },
      "source": [
        "b[a == b]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54bQky1bYKAf"
      },
      "source": [
        "Elementwise application of the **universal functions**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWnGSuUhYKAf"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ZyxZBNYKAl"
      },
      "source": [
        "a.sin()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SScTSkJMYKAo"
      },
      "source": [
        "torch.sin(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bYVYVV7YKAr"
      },
      "source": [
        "a.tan()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-rYL8HQYKAt"
      },
      "source": [
        "a.exp()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbiCDYUzYKAw"
      },
      "source": [
        "a.log()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh1sySpiYKAy"
      },
      "source": [
        "b = -a\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNU0UxqIYKA2"
      },
      "source": [
        "b.abs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqERQjISYKA9"
      },
      "source": [
        "* The sum, mean, max, min:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLmJGdl9YKA-"
      },
      "source": [
        "a.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ervIuNGnYKBD"
      },
      "source": [
        "a.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qxkdUQ2YKBF"
      },
      "source": [
        "Along axis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzU2H7jBbdS-"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6RjJYeYKBG"
      },
      "source": [
        "a.sum(dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgi5BmhOYKBJ"
      },
      "source": [
        "a.sum(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tIkcTENYKBK"
      },
      "source": [
        "a.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4U_LyyPYKBL"
      },
      "source": [
        "a.max(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSqmVtWjYKBO"
      },
      "source": [
        "a.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeA2hlZ2YKBP"
      },
      "source": [
        "a.min(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys-9hnr4YKBS"
      },
      "source": [
        "**Note:** the second tensor returned by `.max()` and `.min()` contains the indices of max/min elements along this axis. E.g. in that case `a.min()` returned `(1, 2, 3)` which are the minimum elements along 0 axis (along columns) and their indices along 0 axis are `(0, 0, 0)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kepFeTZ0YKBV"
      },
      "source": [
        "## Matrix operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RYm3mdrYKBX"
      },
      "source": [
        "* Transpose a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8-1TSkeYKBY"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSAZwai7YKBa"
      },
      "source": [
        "a.t()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqsPkleRYKBd"
      },
      "source": [
        "It is not not the inplace operation too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRPamd2EYKBe"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8YhoxHPYKBh"
      },
      "source": [
        "* Dot product of vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1pRtl7HYKBi"
      },
      "source": [
        "a = torch.FloatTensor([1, 2, 3, 4, 5, 6])\n",
        "b = torch.FloatTensor([-1, -2, -4, -6, -8, -10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcS-28dwYKBp"
      },
      "source": [
        "a.dot(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBiRR1V3LP-r"
      },
      "source": [
        "a.shape, b.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXyhOelQYKBs"
      },
      "source": [
        "a @ b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxqg4xhoYKBt"
      },
      "source": [
        "type(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v2ZjPqDYKBz"
      },
      "source": [
        "type(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsWB9vTuYKB0"
      },
      "source": [
        "type(a @ b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSrnLwkGYKB1"
      },
      "source": [
        "* Matrix product:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViurnbjPYKB2"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "b = torch.FloatTensor([[-1, -2, -3], [-10, -20, -30], [100, 200, 300]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TrCnfWiYKB3"
      },
      "source": [
        "a.mm(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMzIz-_MYKB4"
      },
      "source": [
        "a @ b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig2pr52xYKB5"
      },
      "source": [
        "Remain unchanged:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22QOePSyYKB6"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHr6eKADYKB6"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtuvt20-YKB8"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3], [10, 20, 30], [100, 200, 300]])\n",
        "b = torch.FloatTensor([[-1], [-10], [100]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdDnu5XjYKB9"
      },
      "source": [
        "print(a.shape, b.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD4N4WN8YKB_"
      },
      "source": [
        "a @ b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va9w-BavYKCB"
      },
      "source": [
        "If we unroll the tensor `b` in an array (`torch.view(-1)`) the multiplication would be like with the column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7KsdYcBYKCC"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7k6spayYKCF"
      },
      "source": [
        "b.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u8xQ20bYKCH"
      },
      "source": [
        "a @ b.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCu1sJEYKCJ"
      },
      "source": [
        "a.mv(b.view(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZitrCN6YKCL"
      },
      "source": [
        "## From NumPy to PyTorch conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnLS4CGXYKCL"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.random.rand(3, 3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXge57waYKCM"
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvcr3ymPYKCN"
      },
      "source": [
        "**NOTE!** `a` and `b` have the same data storage, so the changes in one tensor will lead to the changes in another:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N_ZW6TQYKCN"
      },
      "source": [
        "b -= b\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzUnCKsiYKCP"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al73RqKSYKCR"
      },
      "source": [
        "**From PyTorch to NumPy conversion:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5rngw4vYKCR"
      },
      "source": [
        "a = torch.FloatTensor(2, 3, 4)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjK68Kk-YKCS"
      },
      "source": [
        "type(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viLUF7gQYKCU"
      },
      "source": [
        "x = a.numpy()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HxgiLxKYKCV"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdW5bhmeYKCX"
      },
      "source": [
        "type(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbCc-vnWDj1l"
      },
      "source": [
        "x -= x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui-4DptBDlet"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-KS81rUYKCY"
      },
      "source": [
        "Let's write the `forward_pass(X, w)` ($w_0$ is a part of the $w$) for a single neuron (activation = sigmoid) using PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkaIwpn6YKCY"
      },
      "source": [
        "# Ð’Ð°Ñˆ ÐºÐ¾Ð´\n",
        "def forward_pass(X, w):\n",
        "    return torch.sigmoid(X @ w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyqlDItxYKCZ"
      },
      "source": [
        "X = torch.FloatTensor([[-5, 5],\n",
        "                       [2, 3],\n",
        "                       [1, -1]])\n",
        "\n",
        "w = torch.FloatTensor([[-0.5],\n",
        "                       [2.5]])\n",
        "\n",
        "result = forward_pass(X, w)\n",
        "print('result: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzLVLQ2GYKCa"
      },
      "source": [
        "## CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrIicAAiYKCa"
      },
      "source": [
        "[CUDA documentation](https://docs.nvidia.com/cuda/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nDkAG6NYKCa"
      },
      "source": [
        "We can use both CPU (Central Processing Unit) and GPU (Graphical Processing Unit) to make the computations with PyTorch. We can switch between them easily, this is one of the most important things in PyTorch framework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Nsl2IoYKCa"
      },
      "source": [
        "x = torch.FloatTensor(1024, 1024).uniform_()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVr5_SAdYKCb"
      },
      "source": [
        "x.is_cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAy8GGXAYKCd"
      },
      "source": [
        "Place a tensor on GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UGKZbfyYKCd"
      },
      "source": [
        "x = x.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue2SLd9nYKCd"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVVp6BnbD7fy"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "x = x.to(device)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI73B59PYKCg"
      },
      "source": [
        "Let's multiply two tensors on GPU and then move the result on the CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS4QxJJoYKCg"
      },
      "source": [
        "a = torch.FloatTensor(10000, 10000).uniform_()\n",
        "b = torch.FloatTensor(10000, 10000).uniform_()\n",
        "c = a.cuda().mul(b.cuda()).cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ImlgEbwYKCg"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DAN9MhDYKCh"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWc-PiA9YKCi"
      },
      "source": [
        "Tensors placed on CPU and tensors placed on GPU are unavailable for each other:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lwV1sgSYKCi"
      },
      "source": [
        "a = torch.FloatTensor(10000, 10000).uniform_().cpu()\n",
        "b = torch.FloatTensor(10000, 10000).uniform_().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6tYdYtTYKCj"
      },
      "source": [
        "a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEtwaIxDYKCk"
      },
      "source": [
        "Example of working with GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJgVfAbUYKCk",
        "scrolled": true
      },
      "source": [
        "x = torch.FloatTensor(5, 5, 5).uniform_()\n",
        "\n",
        "# check for CUDA availability (NVIDIA GPU)\n",
        "if torch.cuda.is_available():\n",
        "    # get the CUDA device name\n",
        "    device = torch.device('cuda')          # CUDA-device object\n",
        "    y = torch.ones_like(x, device=device)  # create a tensor on GPU\n",
        "    x = x.to(device)                       # or just `.to(\"cuda\")`\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    # you can set the type while `.to` operation\n",
        "    print(z.to(\"cpu\", torch.double))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFg82MJIYKCl"
      },
      "source": [
        "## Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpOWYK-YKCm"
      },
      "source": [
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEDz971fYKCn"
      },
      "source": [
        "The examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYWqXsAjYKCn"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 3, 3, 10\n",
        "\n",
        "# Create random Tensors to hold input and outputs.\n",
        "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
        "# with respect to these Tensors during the backward pass.\n",
        "\n",
        "# Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ\n",
        "\n",
        "# Create random Tensors for weights.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "\n",
        "# Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ\n",
        "\n",
        "\n",
        "# ÐŸÐ¾ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð»Ð¾ÑÑ\n",
        "# Ð’Ð°Ñˆ ÐºÐ¾Ð´ Ð·Ð´ÐµÑÑŒ\n",
        "\n",
        "print(loss)\n",
        "# calculate the gradients\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr19Gh3ZU2Ws"
      },
      "source": [
        "loss.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLkn5C7JYKCp"
      },
      "source": [
        "w1.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYkrFbD5YKCq"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouMNnbtXYKCr"
      },
      "source": [
        "y.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIsqxWIvYKCs"
      },
      "source": [
        "**NOTE:** the gradients are placed into the `.grad` field of tensors (variables) on which gradients were calculated. Gradients *are not placed* in the variable `loss` here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wU_TFedYKCt"
      },
      "source": [
        "w1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6wcpIygtlp8"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "Any self-respecting DL framework must do your backprop for you. Torch handles this with the `autograd` module.\n",
        "\n",
        "The general pipeline looks like this:\n",
        "* When creating a tensor, you mark it as `requires_grad`:\n",
        "    * __```torch.zeros(5, requires_grad=True)```__\n",
        "    * torch.tensor(np.arange(5), dtype=torch.float32, requires_grad=True)\n",
        "* Define some differentiable `loss = arbitrary_function(a)`\n",
        "* Call `loss.backward()`\n",
        "* Gradients are now available as ```a.grads```\n",
        "\n",
        "__Here's an example:__ let's fit a linear regression on Boston house prices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn==1.1.3"
      ],
      "metadata": {
        "id": "0ixUXiXRlJeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# %matplotlib inline\n",
        "# import matplotlib.pyplot as plt\n",
        "# import torch"
      ],
      "metadata": {
        "id": "gRYgNFjHlrdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qc73QI8htlp8"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "plt.scatter(boston.data[:, -1], boston.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYYdcm7RtlqE"
      },
      "source": [
        "If you compute gradient from multiple losses, the gradients will add up at variables, therefore it's useful to __zero the gradients__ between iteratons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDZUerRbtlqE"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "lr = 0.05\n",
        "\n",
        "# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ (Ð’Ð°Ñˆ ÐºÐ¾Ð´)\n",
        "\n",
        "\n",
        "    # loss (Ð’Ð°Ñˆ ÐºÐ¾Ð´)\n",
        "\n",
        "\n",
        "    # Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð²ÐµÑÐ¾Ð² (Ð’Ð°Ñˆ ÐºÐ¾Ð´)\n",
        "\n",
        "\n",
        "    # Ð¾Ð±Ð½ÑƒÐ»ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð° (Ð’Ð°Ñˆ ÐºÐ¾Ð´)\n",
        "\n",
        "\n",
        "    # the rest of code is just bells and whistles\n",
        "    if (i+1)%5==0:\n",
        "        clear_output(True)\n",
        "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
        "        plt.scatter(x.data.numpy(), y_pred.data.numpy(), color='orange', linewidth=5)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"loss = \", loss.data.numpy())\n",
        "        if loss.data.numpy() < 0.1:\n",
        "            print(\"Done!\")\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsOPLQjstlqI"
      },
      "source": [
        "\n",
        "Suprizingly, we were walking really close to the edge. Look a few cells above. We have divided the `x` values by 10 times. Let's what happens if we don't:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9kTfv_FtlqK"
      },
      "source": [
        "plt.plot([element[0] for element in grad_history], )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bz0IJvMtlqM"
      },
      "source": [
        "print(grad_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOOUJ7OGtlqO"
      },
      "source": [
        "# High-level pytorch\n",
        "\n",
        "So far we've been dealing with low-level torch API. While it's absolutely vital for any custom losses or layers, building large neura nets in it is a bit clumsy.\n",
        "\n",
        "Luckily, there's also a high-level torch interface with a pre-defined layers, activations and training algorithms.\n",
        "\n",
        "We'll cover them as we go through a simple image recognition problem\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aR-dnbfhLA0"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "dataset = load_digits()\n",
        "\n",
        "features = dataset.data\n",
        "target = dataset.target\n",
        "\n",
        "features.shape, target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEkKXaPghnFk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oobtHFauhV09"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25)\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIbdnAtmlCxc"
      },
      "source": [
        "binary_train_mask = (y_train == 0) | (y_train == 1)\n",
        "X_train = X_train[binary_train_mask]\n",
        "y_train = y_train[binary_train_mask]\n",
        "\n",
        "binary_test_mask = (y_test == 0) | (y_test == 1)\n",
        "X_test = X_test[binary_test_mask]\n",
        "y_test = y_test[binary_test_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobaNMfwl71J"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FuZXXLjbtlqR"
      },
      "source": [
        "for i in [0,1]:\n",
        "    plt.subplot(1, 2, i + 1)\n",
        "    plt.imshow(X_train[i].reshape([8,8]))\n",
        "    plt.title(str(y_train[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKiKSQ79tlqS"
      },
      "source": [
        "Let's start with layers. The main abstraction here is __`torch.nn.Module`__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttRJjJs_tlqT"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(nn.Module.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEmSZsDZtlqV"
      },
      "source": [
        "There's a vast library of popular layers and architectures already built for ya'.\n",
        "\n",
        "This is a binary classification problem, so we'll train a __Logistic Regression with sigmoid__.\n",
        "$$P(y_i | X_i) = \\sigma(W \\cdot X_i + b) ={ 1 \\over {1+e^{- [W \\cdot X_i + b]}} }$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leM1EYfktlqV"
      },
      "source": [
        "# create a network that stacks layers on top of each other\n",
        "model = nn.Sequential()\n",
        "\n",
        "# add first \"dense\" layer with 64 input units and 1 output unit.\n",
        "model.add_module('l1', nn.Linear(64, 1))\n",
        "\n",
        "# add softmax activation for probabilities. Normalize over axis 1\n",
        "# note: layer names must be unique\n",
        "model.add_module('l2', nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAJ-mrBmtlqX"
      },
      "source": [
        "print(\"Weight shapes:\", [w.shape for w in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRH_sF7ktlqY"
      },
      "source": [
        "# create dummy data with 3 samples and 64 features\n",
        "x = torch.tensor(X_train[:3], dtype=torch.float32)\n",
        "y = torch.tensor(y_train[:3], dtype=torch.float32)\n",
        "\n",
        "# compute outputs given inputs, both are variables\n",
        "y_predicted = model(x)[:, 0]\n",
        "\n",
        "y_predicted # display what we've got"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjHKEOPVtlqb"
      },
      "source": [
        "Let's now define a loss function for our model.\n",
        "\n",
        "The natural choice is to use binary crossentropy (aka logloss, negative llh):\n",
        "$$ L = {1 \\over N} \\underset{X_i,y_i} \\sum - [  y_i \\cdot log P(y_i | X_i) + (1-y_i) \\cdot log (1-P(y_i | X_i)) ]$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKbhK9xPi9QS"
      },
      "source": [
        "F.binary_cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuNs0mkJi-KJ"
      },
      "source": [
        "loss = F.binary_cross_entropy(y_predicted, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6byRX88jWWi"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy9e-ao3tlqd"
      },
      "source": [
        "__Note:__ you can also find many such functions in `torch.nn.functional`, just type __`F.<tab>`__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eMQkQn5tlqf"
      },
      "source": [
        "__Torch optimizers__\n",
        "\n",
        "When we trained Linear Regression above, we had to manually .zero_() gradients on both our variables. Imagine that code for a 50-layer network.\n",
        "\n",
        "Again, to keep it from getting dirty, there's `torch.optim` module with pre-implemented algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuAJeoWJtlqf"
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# here's how it's used:\n",
        "loss.backward()      # add new gradients\n",
        "opt.step()           # change weights\n",
        "opt.zero_grad()      # clear gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l8FK4Jotlqh"
      },
      "source": [
        "# dispose of old variables to avoid bugs later\n",
        "del x, y, y_predicted, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAF1RRDQtlqj"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94onjnoitlqj"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# create network again just in case\n",
        "model = nn.Sequential()\n",
        "model.add_module('first', nn.Linear(64, 1))\n",
        "model.add_module('second', nn.Sigmoid())\n",
        "\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQrBc7-8tlql"
      },
      "source": [
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "    # sample 256 random images\n",
        "\n",
        "\n",
        "    # predict probabilities\n",
        "\n",
        "\n",
        "    assert y_predicted.dim() == 1, \"did you forget to select first column with [:, 0]\"\n",
        "\n",
        "    # compute loss, just like before\n",
        "\n",
        "\n",
        "    # compute gradients\n",
        "\n",
        "\n",
        "    # SGD step\n",
        "\n",
        "\n",
        "\n",
        "    # clear gradients\n",
        "\n",
        "\n",
        "\n",
        "    history.append(loss.data.numpy())\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(\"step #%i | mean loss = %.3f\" % (i, np.mean(history[-10:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMfCCIK9tlqm"
      },
      "source": [
        "__Debugging tips:__\n",
        "* make sure your model predicts probabilities correctly. Just print them and see what's inside.\n",
        "* don't forget _minus_ sign in the loss function! It's a mistake 99% ppl do at some point.\n",
        "* make sure you zero-out gradients after each step. Srsly:)\n",
        "* In general, pytorch's error messages are quite helpful, read 'em before you google 'em.\n",
        "* if you see nan/inf, print what happens at each iteration to find our where exactly it occurs.\n",
        "  * If loss goes down and then turns nan midway through, try smaller learning rate. (Our current loss formula is unstable).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xElZ89X4tlqm"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Let's see how our model performs on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGr-vhOvkjRk"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoOhThpMtlqn"
      },
      "source": [
        "# use your model to predict classes (0 or 1) for all test samples\n",
        "predicted_y_test = model(torch.tensor(X_test, dtype=torch.float32))[:, 0]\n",
        "predicted_y_test = np.array(predicted_y_test > 0.5)\n",
        "\n",
        "assert isinstance(predicted_y_test, np.ndarray), \"please return np array, not %s\" % type(predicted_y_test)\n",
        "assert predicted_y_test.shape == y_test.shape, \"please predict one class for each test sample\"\n",
        "assert np.in1d(predicted_y_test, y_test).all(), \"please predict class indexes\"\n",
        "\n",
        "accuracy = np.mean(predicted_y_test == y_test)\n",
        "\n",
        "print(\"Test accuracy: %.5f\" % accuracy)\n",
        "assert accuracy > 0.95, \"try training longer\"\n",
        "\n",
        "print('Great job!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h69jtVpbtlqp"
      },
      "source": [
        "### More about pytorch:\n",
        "* Using torch on GPU and multi-GPU - [link](http://pytorch.org/docs/master/notes/cuda.html)\n",
        "* More tutorials on pytorch - [link](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "* Pytorch examples - a repo that implements many cool DL models in pytorch - [link](https://github.com/pytorch/examples)\n",
        "* Practical pytorch - a repo that implements some... other cool DL models... yes, in pytorch - [link](https://github.com/spro/practical-pytorch)\n",
        "* And some more - [link](https://www.reddit.com/r/pytorch/comments/6z0yeo/pytorch_and_pytorch_tricks_for_kaggle/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J094WEHQYKCv"
      },
      "source": [
        "# Ð¡ÑÑ‹Ð»ÐºÐ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftVUTfvUYKCv"
      },
      "source": [
        "*1). Official PyTorch tutorials: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovymy5F6YKCw"
      },
      "source": [
        "*2). arXiv article about the deep learning frameworks comparison: https://arxiv.org/pdf/1511.06435.pdf*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXEEowQAYKCx"
      },
      "source": [
        "*3). Useful repo with different tutorials: https://github.com/yunjey/pytorch-tutorial*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cROZcrYYKC0"
      },
      "source": [
        "*4). Facebook AI Research (main contributor of PyTorch) website: https://facebook.ai/developers/tools*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y4MI83p-0Ql"
      },
      "source": [
        "# Ð§Ñ‚Ð¾ Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ:\n",
        "- [Regularized Logistic Regression is Strictly Convex](http://www.qwone.com/~jason/writing/convexLR.pdf)\n",
        "- [SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives\n",
        "](https://www.di.ens.fr/~fbach/Defazio_NIPS2014.pdf)\n",
        "- [Ð›ÐµÐºÑ†Ð¸Ð¸ Ð•Ð²Ð³ÐµÐ½Ð¸Ñ Ð¡Ð¾ÐºÐ¾Ð»Ð¾Ð²Ð°](https://github.com/esokolov/ml-course-hse/tree/master/2018-fall/lecture-notes)"
      ]
    }
  ]
}